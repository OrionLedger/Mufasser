{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e6c709",
   "metadata": {},
   "source": [
    "# Agentic Enterprise Knowledge Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b2d0d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import TypedDict, List, Optional\n",
    "from langchain.schema import Document\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import FastEmbedEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7464b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGState(TypedDict):\n",
    "    question: str\n",
    "    query_type: str\n",
    "    retrieved_docs: List[Document]\n",
    "    search_query: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef333d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_faiss_index(docs_path:str)->FAISS:\n",
    "    loader = DirectoryLoader(docs_path, glob=\"**/*\")\n",
    "    documents = loader.load()\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=150,\n",
    "    )\n",
    "\n",
    "    chunks = splitter.split_documents(documents)\n",
    "\n",
    "    embeddings = FastEmbedEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ec4ed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"mistralai/mistral-7b-instruct:free\",  # Specify any model available on OpenRouter\n",
    "    temperature=0.7,\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "\n",
    "query_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You classify enterprise questions for document retrieval.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "def query_analyzer(state: RAGState):\n",
    "    response = llm.invoke(\n",
    "        query_prompt.format_messages(question=state['question'])\n",
    "    )\n",
    "\n",
    "    state[\"query_type\"] = 'retrieval'\n",
    "    state[\"search_query\"] = state[\"question\"]\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9ecc5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever_agent(vectorstore: FAISS, k: int = 5):\n",
    "    def _retrieve(state: RAGState) -> RAGState:\n",
    "        docs = vectorstore.similarity_search(\n",
    "            state['search_query'], k=k\n",
    "        )\n",
    "        state[\"retrieved_docs\"] = docs\n",
    "\n",
    "        return state\n",
    "    return _retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7cc0eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"Answer ONLY using the provided context. \"\n",
    "     \"If the answer is not in the context, say so explicitly.\"),\n",
    "    (\"human\",\n",
    "     \"Question:\\n{question}\\n\\nContext:\\n{context}\")\n",
    "])\n",
    "\n",
    "def answer_agent(state:RAGState) -> RAGState:\n",
    "    context = \"\\n\\n\".join(\n",
    "        doc.page_content for doc in state[\"retrieved_docs\"]\n",
    "    )\n",
    "    response = llm.invoke(\n",
    "        answer_prompt.format_messages(\n",
    "            question = state['question'],\n",
    "            context = context\n",
    "        )\n",
    "    )\n",
    "    state['answer'] = response.content\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "803383ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rag_graph(vectorstore: FAISS):\n",
    "    graph = StateGraph(RAGState)\n",
    "\n",
    "\n",
    "    graph.add_node(\"analyze_query\", query_analyzer)\n",
    "    graph.add_node(\"retrieve\", retriever_agent(vectorstore))\n",
    "    graph.add_node(\"answer\", answer_agent)\n",
    "\n",
    "    graph.add_edge(START, \"analyze_query\")\n",
    "    graph.add_edge(\"analyze_query\", \"retrieve\")\n",
    "    graph.add_edge(\"retrieve\", \"answer\")\n",
    "    graph.add_edge(\"answer\", END)\n",
    "\n",
    "    return graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e200080f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Our company's AI use policy is outlined in Section 3 of the provided context. The policy includes approved uses (software development, data analysis, customer support), prohibited uses (hiring/termination decisions, processing highly sensitive personal data, generating legally binding documents), and restrictions on model training (enterprise data cannot be used to train external AI models without approval).\n"
     ]
    }
   ],
   "source": [
    "vectorstore = build_faiss_index(\"./enterprise_docs\")\n",
    "rag_app = build_rag_graph(vectorstore)\n",
    "\n",
    "result = rag_app.invoke({\n",
    "    \"question\": \"What is our company's AI use policy?\",\n",
    "    \"retrieved_docs\": [],\n",
    "    \"answer\": None,\n",
    "    \"query_type\": None,\n",
    "    \"search_query\": None\n",
    "})\n",
    "\n",
    "print(result[\"answer\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_enterprise_knowledge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
